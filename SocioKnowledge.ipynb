{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from socioknowledge.study import Study\n",
    "from socioknowledge.dictionary import Dictionary, DictionaryExpansion, ConceptNetDictionaryExpansion\n",
    "from socioknowledge.stream import Stream, TwitterStream\n",
    "from socioknowledge.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "\n",
    "# SocioKnowledge\n",
    "os.environ['SE_ENV'] = 'development'\n",
    "os.environ['SE_BUCKET_URL'] = 's3n://socioknowledge/'\n",
    "# os.environ['SE_BUCKET_URL'] = 'data/'\n",
    "\n",
    "# Digital Ocean\n",
    "os.environ['DO_ACCESS_TOKEN'] = 'c1a723fa16efb34d0cdf417dc1bc3b3a26e3bc709b6635044a67b7b089b4c7ee'\n",
    "\n",
    "# AWS\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIAJIZUY33KIRTBN7SA'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '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'\n",
    "\n",
    "# SPARK\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python2.7'\n",
    "\n",
    "# SPARK LOCAL\n",
    "# os.environ['SPARK_MASTER'] = 'local[3]'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.11.119,org.apache.hadoop:hadoop-aws:2.7.3,org.elasticsearch:elasticsearch-spark-20_2.11:6.0.0-alpha-1,org.mongodb.mongo-hadoop:mongo-hadoop-spark:2.0.2 pyspark-shell'\n",
    "\n",
    "# SPARK CLUSTER\n",
    "os.environ['SPARK_MASTER'] = 'spark://spark-master:7077'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--driver-cores 2 --driver-memory 4gb --num-executors 5 --executor-cores 2 --executor-memory 3gb --packages com.amazonaws:aws-java-sdk:1.11.119,org.apache.hadoop:hadoop-aws:2.7.3,org.elasticsearch:elasticsearch-spark-20_2.11:6.0.0-alpha-1,org.mongodb.mongo-hadoop:mongo-hadoop-spark:2.0.2 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--num-executors 3 --executor-cores 4gb --executor-memory 6gb --packages com.amazonaws:aws-java-sdk:1.11.119,org.apache.hadoop:hadoop-aws:2.7.3,org.elasticsearch:elasticsearch-spark-20_2.11:6.0.0-alpha-1,org.mongodb.mongo-hadoop:mongo-hadoop-spark:2.0.2 pyspark-shell'\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--num-executors 3 --executor-memory 4gb --packages com.amazonaws:aws-java-sdk:1.11.119,org.apache.hadoop:hadoop-aws:2.7.3,org.elasticsearch:elasticsearch-spark-20_2.11:6.0.0-alpha-1,org.mongodb.mongo-hadoop:mongo-hadoop-spark:2.0.2 pyspark-shell'\n",
    "\n",
    "# MongoDB\n",
    "os.environ['MONGO_URL'] = 'mongodb://mongo-cluster/socioknowledge'\n",
    "\n",
    "# ElasticSearch\n",
    "os.environ['ES_HOST'] = 'elasticsearch'\n",
    "os.environ['ES_PORT'] = '9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study: energy-consumption\n",
      "Bucket URL: s3n://socioknowledge/\n",
      "Bucket Dataset URL: s3n://socioknowledge/datasets/\n",
      "Bucket Study URL: s3n://socioknowledge/studies/energy-consumption/\n"
     ]
    }
   ],
   "source": [
    "# Initialize Study\n",
    "study = Study('energy-consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary\n",
    "dictionary = Dictionary(study)\n",
    "dictionary.load(\"dictionary-seeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and filter dictionary\n",
    "dictionary.tokenize()\n",
    "dictionary.filter_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conceptnet expansion\n",
    "expansion = ConceptNetDictionaryExpansion(\\\n",
    "    dictionary=dictionary,\\\n",
    "    input_col=\"term_tokenized\",\\\n",
    "    valid_min_weight=0.5,\\\n",
    "    valid_languages=['en','nl','id','ms']\n",
    ")\n",
    "dictionary.expand(expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# dictionary.filter_stemming()\n",
    "\n",
    "# Export raw\n",
    "# dictionary.export_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.compile(max_tokens_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary.dictionary.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary.compiled.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.compiled.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11:27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Stream\n",
    "stream = Stream(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitterStream = TwitterStream(study)\n",
    "twitterStream.load_from_mongo(collection='tweets', query='{}')\n",
    "# twitterStream.load_from_mongo(collection='tweets', query='{}', limit=2)\n",
    "# twitterStream.load_from_mongo(collection=\"tweets\", query=\"{'place.country_code':'NL'}\", limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.concat(twitterStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filters\n",
    "stream.tokenize()\n",
    "stream.filter_standard()\n",
    "# stream.stream.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.filter_stopwords()\n",
    "# stream.stream.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.filter_stemming()\n",
    "# stream.stream.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stream.filter_shingle(max_n=2)\n",
    "# stream.stream.show(20, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match with the dictionary\n",
    "stream.match_dictionary(dictionary)\n",
    "# stream.stream.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream.stream.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = stream.export_dataset()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.dataset.select(\"label\",\"tokens\").show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature extractions\n",
    "dataset.extract_tf_idf(num_features=100)\n",
    "# dataset.extract_pca(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.dataset.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset to train whether stream related to energy consumption or not\n",
    "ec_labels = [\n",
    "    [\"none\"],\n",
    "    [\"food\", \"mobility\",\"dwelling\",\"leisure\"]\n",
    "]\n",
    "dataset_ec = dataset.transform_binomial(labels=ec_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset to train whether stream related to mobility energy consumption or not\n",
    "mobility_labels = [\n",
    "    [\"none\"],\n",
    "    [\"mobility\"]\n",
    "]\n",
    "dataset_mobility = dataset.transform_binomial(labels=mobility_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset to train whether stream related to mobility energy consumption or not\n",
    "leisure_labels = [\n",
    "    [\"none\"],\n",
    "    [\"leisure\"]\n",
    "]\n",
    "dataset_leisure = dataset.transform_binomial(labels=leisure_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_ec.select('label','tokens').show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, test_data = dataset_ec.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import col, udf, lit, array, struct, create_map, split, explode\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, DoubleType, IntegerType, LongType, StringType, \\\n",
    "    DateType, DataType, BooleanType\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected = predictions.select(\"id\", \"tokens\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    rid, text, prob, prediction = row\n",
    "    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"raw_prediction\")\n",
    "# accuracy = evaluator.evaluate(predictions)\n",
    "# print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
